{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f07a678-1e6e-430a-aabe-f76e7a469746",
   "metadata": {},
   "source": [
    "# Handling Multiple Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326cc365-0d54-4efa-b4d9-01e3dfee119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anubhavmaity/mambaforge/envs/transformers-course/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc384bf1-a0c8-4085-9b4c-283ce35240fd",
   "metadata": {},
   "source": [
    "## Model expects a batch of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1976b66f-8847-419a-8ce0-e2ecfce6cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1316390-fd54-47ad-a9ff-60c7679dd3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = '''\n",
    "Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim\n",
    "Because it was grassy and wanted wear,\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way\n",
    "I doubted if I should ever come back.\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I,\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6af0d45-4bc7-4e2b-b401-bae2bc9146ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(poem)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a7e492-bf99-4867-a960-11c98609847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac19edb-cda2-4a02-a507-22d6b1f66fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(input_ids)\n",
    "## it will fail because the input_ids is not batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16aaa869-5e6b-4c53-8a42-0859067cceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = tokenizer(poem, return_tensors=\"pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3120afa5-fba3-4c4c-b1da-46db56a86a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2048,  4925, 17856,  5999,  1999,  1037,  3756,  3536,  1010,\n",
       "          1998,  3374,  1045,  2071,  2025,  3604,  2119,  1998,  2022,  2028,\n",
       "         20174,  1010,  2146,  1045,  2768,  1998,  2246,  2091,  2028,  2004,\n",
       "          2521,  2004,  1045,  2071,  2000,  2073,  2009,  6260,  1999,  1996,\n",
       "          2104, 26982,  1025,  2059,  2165,  1996,  2060,  1010,  2004,  2074,\n",
       "          2004,  4189,  1010,  1998,  2383,  3383,  1996,  2488,  4366,  2138,\n",
       "          2009,  2001, 22221,  1998,  2359,  4929,  1010,  2295,  2004,  2005,\n",
       "          2008,  1996,  4458,  2045,  2018,  6247,  2068,  2428,  2055,  1996,\n",
       "          2168,  1010,  1998,  2119,  2008,  2851,  8053,  3913,  1999,  3727,\n",
       "          2053,  3357,  2018, 19817,  7716,  4181,  2304,  1012,  2821,  1010,\n",
       "          1045,  2921,  1996,  2034,  2005,  2178,  2154,   999,  2664,  4209,\n",
       "          2129,  2126,  5260,  2006,  2000,  2126,  1045, 12979,  2065,  1045,\n",
       "          2323,  2412,  2272,  2067,  1012,  1045,  4618,  2022,  4129,  2023,\n",
       "          2007,  1037,  6682,  4873,  5535,  1998,  5535,  6516,  1024,  2048,\n",
       "          4925, 17856,  5999,  1999,  1037,  3536,  1010,  1998,  1045,  1010,\n",
       "          1045,  2165,  1996,  2028,  2625,  6158,  2011,  1010,  1998,  2008,\n",
       "          2038,  2081,  2035,  1996,  4489,  1012,   102]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "248c7a4c-235b-4e60-8c69-063bc37851f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03cce03-66b6-4df0-9b8d-59734c80cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a5e3b4-8765-4428-9ce6-9564d828e45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2048,  4925, 17856,  5999,  1999,  1037,  3756,  3536,  1010,  1998,\n",
       "          3374,  1045,  2071,  2025,  3604,  2119,  1998,  2022,  2028, 20174,\n",
       "          1010,  2146,  1045,  2768,  1998,  2246,  2091,  2028,  2004,  2521,\n",
       "          2004,  1045,  2071,  2000,  2073,  2009,  6260,  1999,  1996,  2104,\n",
       "         26982,  1025,  2059,  2165,  1996,  2060,  1010,  2004,  2074,  2004,\n",
       "          4189,  1010,  1998,  2383,  3383,  1996,  2488,  4366,  2138,  2009,\n",
       "          2001, 22221,  1998,  2359,  4929,  1010,  2295,  2004,  2005,  2008,\n",
       "          1996,  4458,  2045,  2018,  6247,  2068,  2428,  2055,  1996,  2168,\n",
       "          1010,  1998,  2119,  2008,  2851,  8053,  3913,  1999,  3727,  2053,\n",
       "          3357,  2018, 19817,  7716,  4181,  2304,  1012,  2821,  1010,  1045,\n",
       "          2921,  1996,  2034,  2005,  2178,  2154,   999,  2664,  4209,  2129,\n",
       "          2126,  5260,  2006,  2000,  2126,  1045, 12979,  2065,  1045,  2323,\n",
       "          2412,  2272,  2067,  1012,  1045,  4618,  2022,  4129,  2023,  2007,\n",
       "          1037,  6682,  4873,  5535,  1998,  5535,  6516,  1024,  2048,  4925,\n",
       "         17856,  5999,  1999,  1037,  3536,  1010,  1998,  1045,  1010,  1045,\n",
       "          2165,  1996,  2028,  2625,  6158,  2011,  1010,  1998,  2008,  2038,\n",
       "          2081,  2035,  1996,  4489,  1012]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "626f8455-b7be-41a0-a6d6-73f7ae7ad9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7040, -1.4993]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b05a2-5f17-49a6-aa13-77dbd7d98a67",
   "metadata": {},
   "source": [
    "### Multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f6eeb98-f13d-4131-b30a-843e8decedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_ids = [ids, ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d250ba0-f346-4be3-a0ab-9bd266bbcc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_input_ids = torch.tensor(batched_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea953b9e-45d3-4f9c-b282-91c289818ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.7040, -1.4993],\n",
       "        [ 1.7040, -1.4993]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batched_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18590f00-1417-4b71-8751-5bde1d205d43",
   "metadata": {},
   "source": [
    "## Padding the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c276397c-6158-4cfe-890d-d20ce99331ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_ids = [[200, 200, 200], [200, 200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "952c578c-2699-4d62-9143-7d01696207f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_id = 100\n",
    "batched_ids = [[200, 200, 200], [200, 200, padding_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28397f04-a4ee-471a-a52e-f83c20bf32ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75bb626f-20d7-4ef9-8519-76c1349f6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence1_ids = [[200, 200, 200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5a7a52c-93c0-4bd8-949b-fd0df3076d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence2_ids = [[200, 200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a54ba073-7cc8-44b1-b121-f5d1d132b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_ids = [[200, 200, 200],\n",
    "               [200, 200, tokenizer.pad_token_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "839a60d7-d7db-4d2b-8760-825e1a381124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(sequence1_ids)).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "151112b6-7cd4-43f6-a6ce-8927cea6fb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(sequence2_ids)).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d457449f-83ea-4ec2-87e1-e9ac4c75556d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5694, -1.3895],\n",
       "        [ 1.3374, -1.2163]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(batched_ids)).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f02fa-559e-48c0-842b-434cb145c953",
   "metadata": {},
   "source": [
    "## Attention Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6de8a527-4795-4ba1-9af4-4a04af4da1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_ids = [\n",
    "    [200, 200, 200], \n",
    "    [200, 200, tokenizer.pad_token_id]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d967e14-c82a-495b-83f6-0a0fc4a9ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = [\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88e325f5-755a-469a-a293-ebd323cf5e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5694, -1.3895],\n",
       "        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n",
    "outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0290f-93db-4bc2-8cb8-98e5072f7211",
   "metadata": {},
   "source": [
    "## Try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "842f1adb-43ac-4735-870b-2316f92cccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "proverb1 = \"Absence makes the heart grow fonder\"\n",
    "proverb2 = \"Honesty is the best policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "521c67cd-408c-459e-976a-dfaa1f39a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = tokenizer.tokenize(proverb1)\n",
    "ids1 = tokenizer.convert_tokens_to_ids(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90527e4e-c46a-4422-8959-af214855dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = tokenizer.tokenize(proverb2)\n",
    "ids2 = tokenizer.convert_tokens_to_ids(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a738f10f-a954-46d0-a6c1-90dce77db3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6438, 3084, 1996, 2540, 4982, 13545, 2121], 7)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids1, len(ids1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "61cfc74e-cae2-4761-8e52-14f275c8d3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([16718, 2003, 1996, 2190, 3343], 5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids2, len(ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5629e649-18b3-4ac2-951e-5144ee19f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.9582,  4.2422]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1 = model(torch.tensor([ids1])); outputs1.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aebb96d6-95f3-4852-936c-8575d59d31e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7858,  4.1988]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2 = model(torch.tensor([ids2])); outputs2.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724b38b-c985-4b23-8bb2-431dfc3ae1fa",
   "metadata": {},
   "source": [
    "#### Lets batched the two inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a96441d9-9955-4d2c-bd15-a31e8f628d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask1 = [1] * len(ids1)\n",
    "attention_mask2 = [1] * len(ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1c25c34-15db-41bf-a22d-81bb2ef264a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "408207ba-ece1-437b-ad3d-807ed5540b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69c0f644-7fd5-41aa-b3fc-9f94ec810208",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask2.extend([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1759058f-81b3-4d28-ac45-68f99658bd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6b060c5-1c51-4674-9c01-31fd0bc88d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6438, 3084, 1996, 2540, 4982, 13545, 2121]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd4eeef3-8985-4700-9022-66568bab2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2.extend([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4799f9ce-bdde-44a0-aba1-1313ef0a5855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16718, 2003, 1996, 2190, 3343, 0, 0]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f17e5b7e-c106-4bc1-98eb-f9963c55980a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.9582,  4.2422],\n",
       "        [-3.7858,  4.1988]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([ids1, ids2]), attention_mask=torch.tensor([attention_mask1, attention_mask2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0af95-dff3-4613-aeab-7ae160f85c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-course",
   "language": "python",
   "name": "transformers-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
